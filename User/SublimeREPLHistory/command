-dir()
-dir
-dir()
-sys
-import sys
-dir(sys)
-dir()
-dir()
-a
-a = 5\nprint str(a) + "afs"
-a
-dir()
-# -*-coding:utf-8-*-\n# Screippaustesti\n# TODO tyhjien palautusten sijaan virheilmoituksia?\n\n\nfrom lxml import html\nimport time\nimport datetime as dt\nimport logging\nimport sys\n# Jos ohjelmaa ajetaan itsenäisesti, ei voida käyttää app enginen moduuleita;\n# Urlfetch-, Memcache- ja Deferred-luokat mahdollistavat skreippausfunktioiden\n# testaamisen ilman App engineä.\ntry:\n    from google.appengine.api import urlfetch, memcache\n    from google.appengine.ext import deferred\nexcept ImportError:\n    logging.getLogger().setLevel(logging.DEBUG)\n    import urllib2\n\n    class Urlfetch:\n        def fetch(self, url):\n            response = urllib2.urlopen(url)\n\n            class Response:\n                def __init__(self, content, status_code):\n                    self.content = content\n                    self.status_code = status_code\n            return Response(response.read(), response.getcode())\n\n    class Memcache:\n        def get(self, *args, **kwargs):\n            pass\n\n        def add(self, *args, **kwargs):\n            pass\n\n    class Deferred:\n        def defer(self, *args, **kwargs):\n            pass\n    urlfetch = Urlfetch()\n    memcache = Memcache()\n\nCURRENT_SEASON = "2012"\nPLAYOFFS = False\nMONTHS = ["", "jan", "feb", "mar", "apr", "may", "jun",\n          "jul", "aug", "sep", "oct", "nov", "dec"]\nTEAMS = ["njd", "nyi", "nyr", "phi", "pit", "bos", "buf", "mon", "ott", "tor",\n         "car", "fla", "tam", "was", "wpg", "chi", "cob", "det", "nas", "stl",\n         "cgy", "col", "edm", "min", "van", "ana", "dal", "los", "pho", "san"]\nCITIES = ["new jersey", "ny islanders", "ny rangers", "philadelphia",\n          "pittsburgh", "boston", "buffalo", u"montréal", "ottawa", "toronto",\n          "carolina", "florida", "tampa bay", "washington", "winnipeg",\n          "chicago", "columbus", "detroit", "nashville", "st. louis",\n          "calgary", "colorado", "edmonton", "minnesota", "vancouver",\n          "anaheim", "dallas", "los angeles", "phoenix", "san jose"]\n\n# Eri sivuilta poimitaan erilaisia tilastoja:\nGAME_LOG_COLUMNS = ["opponent", "result", "g", "a", "pts", "+/-", "pim",\n                    "ppg", "hits", "bks", "ppa", "shg", "sha", "gw", ",gt",\n                    "sog", "pct"]\nBOXSCORE_COLUMNS_GOALIE = ["sa", "ga", "sv", "sv%", "pim", "toi"]\nBOXSCORE_COLUMNS = ["g", "a", "pts", "+/-", "pim", "s", "bs", "hits", "fw",\n                    "fl", "fo%", "shifts", "toi"]\n\n\ndef scrape_players(query=""):\n    """Skreippaa kaikki pelaajat, joiden nimi vastaa hakuehtoa. Oletuksena\n    haetaan kaikki pelaajat. Paluuarvona dictionary, jossa avaimena\n    pelaajan id, arvoina nimi, pelipaikka ja joukkue."""\n    players = memcache.get("query" + query)\n    if players is not None:\n        return players\n\n    url = "http://sports.yahoo.com/nhl/players?type=lastname&first=1&query="\n    t0 = time.time()\n    response = urlfetch.fetch(url + query)\n    t0 = time.time() - t0\n    if response.status_code != 200:\n        return None\n\n    t1 = time.time()\n    root = html.fromstring(response.content)\n    rows = root.xpath("//table//tr[contains(@class, 'ysprow') and count(td)=3]")\n    players = {}\n    for row in rows:\n        tds = row.getchildren()\n        pid = tds[0].getchildren()[0].attrib["href"].split("/")[-1]\n        name = tds[0].text_content().strip()\n        pos = tds[1].text\n        team = tds[2].getchildren()[0].attrib["href"].split("/")[-1]\n        players[pid] = dict(name=name, pos=pos, team=team)\n\n    memcache.add("query" + query, players, 60 * 60 * 24)\n    logging.info("""scrape_players(%s):\n                 Haettiin HTML ajassa %f\n                 Skreipattiin data ajassa %f"""\n                 % (query, t0, time.time() - t1))\n    return players\n\n\ndef scrape_players_and_stats(year="2012", playoffs=False,\n    positions=["C", "RW", "LW", "D", "G"]):\n    """Skreippaa valitun kauden kaikki pelaajat tilastoineen.\n    Paluuarvona dictionary jossa avaimena pelaajan id, arvona\n    joukkue, nimi ja koko kauden tilastot dictionaryssa."""\n    if year > CURRENT_SEASON or (year == CURRENT_SEASON and playoffs != PLAYOFFS):\n        return {}\n\n    url = "http://sports.yahoo.com/nhl/stats/byposition?pos=%s&year=%s"\n    year = "postseason_" + year if playoffs else "season_" + year\n    all_ids = {}\n\n    positions = map(str.upper, positions)\n\n    if any(pos not in ["C", "RW", "LW", "D", "G"] for pos in positions):\n        return {}  # Virheellinen pelipaikka\n\n    if "G" in positions:  # Maalivahdit täytyy skreipata eri sivulta.\n        if len(positions) > 1:  # Jos haetaan maalivahtien lisäksi muita pelipaikkoja..\n            positions.remove("G")\n            positions = [",".join(positions), "G"]\n    else:\n        positions = [",".join(positions)]\n\n    for position in positions:\n        url0 = url % (position, year)\n        print url0\n        response = urlfetch.fetch(url0)\n        if response.status_code != 200:\n            return {}\n        root = html.fromstring(response.content)\n\n        t0 = time.time()\n        ids = {}\n        rows = root.xpath("//table[count(tr)>10]/tr")\n        columns = [el.text_content().strip().lower() for el in rows[0].xpath("td[*]")]\n        columns = columns[1:]\n        for row in rows[1:]:\n            name = row.xpath("td/a")[0].text_content().lower()\n            pid = row.xpath("td/a")[0].attrib["href"].split("/")[-1]\n            stats = {"name": name}\n            i = 0\n            for td in row.xpath("td")[1:]:\n                text = td.text_content().strip().lower()\n                if text != "":\n                    stats[columns[i]] = text\n                    i += 1\n            ids[pid] = stats\n        all_ids = dict(all_ids.items() + ids.items())\n    return all_ids\n\n\ndef scrape_games_by_player(pid, year="2012"):\n    """Palauttaa pelaajan pelatut pelit. Paluuarvona dictionary, jonka avaimena\n    ottelun id, arvona pelaajan tilastot kyseisestä pelistä."""\n    pid = str(pid)\n    if year > CURRENT_SEASON:\n        return {}\n\n    games = memcache.get(pid + year)\n    if games:\n        logging.info("scrape_player_games(%s, %s) - Loytyi valimuistista."\n            % (pid, year))\n        return games\n    logging.info("scrape_player_games(%s, %s) - Ei loytynyt valimuistista."\n            % (pid, year))\n\n    url = "http://sports.yahoo.com/nhl/players/%s/gamelog?year=%s" % (pid, year)\n    t0 = time.time()\n    response = urlfetch.fetch(url)\n    t0 = time.time() - t0\n    if response.status_code != 200:\n        raise web.notfound()\n\n    t1 = time.time()\n    root = html.fromstring(response.content)\n    games = {}\n    rows = root.xpath("//table/tr[contains(@class, 'ysprow') and position() < last()]")\n    for row in rows:\n        game = {}\n        gid = row.xpath("td/a/@href")[0].split("gid=")[-1]\n        for i, td in enumerate(row.xpath("td")[1:-1]):\n            game[GAME_LOG_COLUMNS[i]] = td.text_content().strip()\n        games[gid] = game  # games == {"123":{"opponent":"asd","g":4,...}, "124":{...}, ...}\n\n    t1 = time.time() - t1\n    logging.info("""scrape_games_by_player(%s, %s):\n                 Haettiin HTML ajassa %f\n                 Skreipattiin data ajassa %f"""\n                 % (pid, year, t0, t1))\n    # Deferred kutsuu add_cache-funktiota asynkronisesti:\n    deferred.defer(add_cache, key=pid + year, value=games)\n    return games\n\n\ndef scrape_games_by_team(team, year="2012"):\n    """Palauttaa dictionaryn jossa avaimena joukkueen PELATTUJEN otteluiden\n    id:t, arvona ottelun 'nimi' (esim. 'Boston Bruins vs Boston (0-1-2)')."""\n    team = team.lower()\n    if not team in TEAMS or year > CURRENT_SEASON:\n        return {}\n\n    games = memcache.get(team + year)\n    if games:\n        logging.info("scrape_player_games(%s, %s) - Loytyi valimuistista."\n            % (team, year))\n        return games\n    logging.info("scrape_player_games(%s, %s) - Ei loytynyt valimuistista."\n            % (team, year))\n\n    url = ("http://sports.yahoo.com/nhl/teams/%s/schedule?"\n           "view=print_list&season=%s") % (team, year)\n    t0 = time.time()\n    response = urlfetch.fetch(url)\n    t0 = time.time() - t0\n    if response.status_code != 200:\n        raise web.notfound()\n\n    t1 = time.time()\n    root = html.fromstring(response.content)\n    rows = root.xpath("//tbody/tr[td[3]/a[contains(@href, 'recap')]]")\n    games = {}\n    for row in rows:\n        href = row.xpath("td[3]/a/@href")[0]\n        gid = href.split("gid=")[-1]  # TODO entä jos gid:n jälkeen toinen parametri?\n        games[gid] = row.xpath("td")[1].text_content().strip()\n\n    t1 = time.time() - t1\n    logging.info("""scrape_games_by_team(%s, %s):\n                 Haettiin HTML ajassa %f\n                 Skreipattiin data ajassa %f"""\n                 % (team, year, t0, t1))\n    # Deferred kutsuu add_cache-funktiota asynkronisesti:\n    deferred.defer(add_cache, key=team + year, value=games)\n    return games\n\n\ndef scrape_game(gid):\n    """Palauttaa dictionaryn, jossa hirveä läjä dataa ottelusta."""\n    gid = str(gid)\n\n    game = memcache.get(gid)\n    if game:\n        logging.info("scrape_game(%s) - Loytyi valimuistista."\n            % (gid))\n        return game\n    logging.info("scrape_game(%s) - Ei loytynyt valimuistista."\n            % (gid))\n\n    t0 = time.time()\n    url = "http://sports.yahoo.com/nhl/boxscore?gid=" + gid\n    response = urlfetch.fetch(url)\n    t0 = time.time() - t0\n    if response.status_code != 200:\n        raise web.notfound()\n\n    t1 = time.time()\n    root = html.fromstring(response.content)\n    game = {}\n    # Ottelun tulos:\n    game["away_team"] = root.xpath("//div[@class='away']//a")[0].attrib["href"].split("/")[-1]\n    game["home_team"] = root.xpath("//div[@class='home']//a")[0].attrib["href"].split("/")[-1]\n    game["away_score"] = root.xpath("//div[@class='away']/*")[0].text_content().strip()\n    game["home_score"] = root.xpath("//div[@class='home']/*")[0].text_content().strip()\n\n    # Maalit ja mahd. shootout:\n    periods = root.xpath("(//div[count(h5)>2])[1]/table")\n    goals, shootout = [], []\n    for i, period in enumerate(periods[:3]):  # Varsinaisen peliajan maalit\n        for tr in period.xpath("tbody/tr[count(td)>3]"):\n            tds = tr.xpath("td")\n            goal = {}\n            goal["period"] = i + 1\n            goal["time"] = tds[0].text_content().strip()\n            goal["team"] = tds[1].xpath("a/@href")[0].split("/")[-1]\n            goal["desc"] = tds[2].text_content().strip()\n            goal["score"] = tds[3].text_content().strip()\n            goals.append(goal)\n    if len(periods) > 3:\n        if len(periods[3].xpath("tbody/tr[count(td)>3]")) != 0:  # Jatkoaika\n            goal = {}\n            goal["period"] = 4\n            goal["time"] = tds[0].text_content().strip()\n            goal["team"] = tds[1].xpath("a/@href")[0].split("/")[-1]\n            goal["desc"] = tds[2].text_content().strip()\n            goal["score"] = tds[3].text_content().strip()\n            goals.append(goal)\n        else:  # Shootout\n            for tr in periods[4].xpath("tbody/tr"):\n                attempt = {}\n                attempt["team"] = tr.xpath("td/a/@href")[0].split("/")[-1]\n                attempt["desc"] = tr.xpath("td[last()]")[0].text_content().strip()\n                shootout.append(attempt)\n    game["goals"], game["shootout"] = goals, shootout\n\n    # Pelaajakohtaiset tilastot:\n    all_goalies = root.xpath("//div[contains(@class, 'goalies')]/table")\n    all_skaters = root.xpath("//div[contains(@class, 'skaters')]/table")\n    for i, team in enumerate(["away", "home"]):\n        team_goalies = {}\n        # Maalivahdit:\n        for tr in all_goalies[i].xpath("tbody/tr"):\n            goalie = {}\n            pid = tr.xpath(".//a/@href")[0].split("/")[-1]  # Id\n            goalie["name"] = tr.xpath(".//a")[0].text       # Nimi\n            for j, td in enumerate(tr.xpath("td")[1:]):     # Tilastot\n                goalie[BOXSCORE_COLUMNS_GOALIE[j]] = td.text_content().strip()\n            team_goalies[pid] = goalie\n        # Loput:\n        team_skaters = {}\n        for tr in all_skaters[i].xpath("tbody/tr"):\n            skater = {}\n            pid = tr.xpath(".//a/@href")[0].split("/")[-1]  # Id\n            skater["name"] = tr.xpath(".//a")[0].text       # Nimi\n            for k, td in enumerate(tr.xpath("td")[1:]):     # Tilastot\n                skater[BOXSCORE_COLUMNS[k]] = td.text_content().strip()\n            team_skaters[pid] = skater\n        game[team] = dict(goalies=team_goalies, skaters=team_skaters)\n\n    t1 = time.time() - t1\n    logging.info("""scrape_game(%s):\n                 Haettiin HTML ajassa %f\n                 Skreipattiin data ajassa %f""" % (gid, t0, t1))\n    memcache.add(gid, game)\n    return game\n\n\ndef scrape_schedule(season="20122013", playoffs=False):\n    """Skreippaa kauden tulevien pelien alkamisajat ja joukkueet.\n\n    Paluuarvo on muotoa\n    {"ana": [\n        {"time": "2012-02-06 21:30:00", "home":"ana", "away":"bos"},\n        {"time": "2012-02-07 16:00:00", "home":"cal", "away":"ana"},\n        ...],\n     "bos": [\n        {"time": "2012-02-06 21:30:00", "home:"ana", "away":"bos"},\n        ...],\n     ...}\n    """\n    schedule = memcache.get("schedule")\n    if schedule is not None:\n        return schedule\n\n    url = "http://nhl.com/ice/schedulebyseason.htm?season=%s"\n    if playoffs:\n        url += "&gameType=3"\n    t0 = time.time()\n    page = urlfetch.fetch(url)\n    t0 = time.time() - t0\n\n    t1 = time.time()\n    root = html.fromstring(page.content)\n    schedule = {team: [] for team in TEAMS}\n    rows = root.xpath("//div[@class='contentBlock']/table[1]/tbody/tr")\n    for row in rows:\n        if row.xpath("td[4]/*"):\n            date_str = row.xpath("td[1]/div[1]/text()")[0][4:]\n            time_str = row.xpath("td[4]/div[1]/text()")[0].replace(" ET", "")\n            datetime_str = str(str_to_date(date_str + " " + time_str))\n        else:\n            # Joidenkin pelien alkamiskellonaika ei ole tiedossa (pvm on),\n            # mitäköhän niille tekisi?\n            datetime_str = ""\n        home_city = row.xpath("td[2]")[0].text_content().lower()\n        away_city = row.xpath("td[3]")[0].text_content().lower()\n        home_team = TEAMS[CITIES.index(home_city)]\n        away_team = TEAMS[CITIES.index(away_city)]\n        game = {"time": datetime_str, "home": home_team, "away": away_team}\n        schedule[home_team].append(game)\n        schedule[away_team].append(game)\n\n    logging.info("""scrape_schedule():\n                 Haettiin HTML ajassa %f\n                 Skreipattiin data ajassa %f""" % (t0, time.time() - t1))\n    memcache.add("schedule", schedule, 60 * 60 * 12)\n    return schedule\n\n\ndef get_next_game(team=None, pid=None):\n    """Palauttaa dictionaryn, jossa joukkueen/pelaajan seuraavan pelin\n    alkamisaika, kotijoukkue ja vierasjoukkue. Esim:\n    {"time": "2013-02-28 10:30:00", "home":"ana", "away":"bos"}}\n    """\n    if pid and not team:\n        team = scrape_players()[pid]["team"]\n    return min(scrape_schedule()[team], key=lambda x: x["time"])\n\n\ndef get_latest_game(team=None, pid=None):\n    """Palauttaa joukkueen/pelaajan viimeisimmän pelatun pelin id:n."""\n    if team:\n        return sorted(scrape_games_by_team(team))[-1]\n    return sorted(scrape_games_by_player(pid))[-1]\n\n\ndef add_cache(key, value):\n    """Lisää arvon välimuistiin, määrittää vanhenemisajan otteluohjelman\n    mukaan. Tallennettava arvo voi olla joko pelaajan tai joukkueen pelatut\n    pelit."""\n    ident, year = key[:-4], key[-4:]\n    if year != CURRENT_SEASON:\n        # Edellisten kausien pelattujen pelien tiedot eivät vanhene:\n        memcache.set(key, value)\n    else:\n        # Muuten asetetaan vanhenemisaika seuraavan ottelun mukaan:\n        previous = memcache.get(key + "b")\n        if previous != None and len(value) == previous:\n            # Jos arvo ei ole muuttunut, laitetaan vanhenemisajaksi 10 minuuttia:\n            memcache.set(key, value, 60 * 10)\n        else:\n            # Arvo on muuttunut, selvitetään seuraavan ottelun ajankohta:\n            if ident.isalpha():\n                next_game_time = get_next_game(team=ident)["time"]\n            else:\n                next_game_time = get_next_game(pid=ident)["time"]\n            # Välimuistin arvo vanhenee 2 tuntia pelin alkamisen jälkeen:\n            game_end_time = isostr_to_date(next_game_time) + dt.timedelta(\n                hours=2)\n            time_diff = (game_end_time - dt.datetime.utcnow()).seconds\n            memcache.set(key, value, time_diff)\n            memcache.set(key + "b", len(value))\n            logging.info("""Tallennettiin valimuistiin\n                         Avain %s\n                         Vanhenemisaika %ds""" % (key, time_diff))\n\n\ndef toi_to_sec(toi):\n    """Peliaka sekunteiksi.\n\n    >>> toi_to_sec("22:18")\n    1338\n    """\n    splits = toi.split(":")\n    return int(splits[0]) * 60 + int(splits[1])\n\n\ndef sec_to_toi(sec):\n    """Sekunnit peliajaksi.\n\n    >>> print sec_to_toi("1234")\n    20:34\n    """\n    sec = int(sec)\n    return "%d:%d" % (sec / 60, sec % 60)\n\n\ndef str_to_date(datetime_str, zone=-5):\n    """Ottaa merkkijonon muotoa "FEB 6, 2013 7:30 PM", palauttaa\n    datetime-objektin. Zone-parametri määrittää merkkijonon aikavyöhykkeen;\n    Jos zone on -5, paluuarvoon lisätään 5 tuntia jolloin paluuarvon aika-\n    vyöhyke on GMT+-0.\n\n    >>> print str_to_date("FEB 6, 2013 7:30 PM", zone=-1)\n    2013-02-06 20:30:00\n    >>> print str_to_date("FEB 28, 2013 12:00 AM", zone=0)\n    2013-02-28 00:00:00\n    """\n    format = "%b %d, %Y %I:%M %p"\n    return dt.datetime.strptime(datetime_str, format) - dt.timedelta(hours=zone)\n\n\ndef isostr_to_date(datetime_str):\n    """Ottaa ISO-formatoidun merkkijonon, palauttaa datetime-objektin.\n\n    >>> print isostr_to_date("2013-02-28 16:12:00")\n    2013-02-28 16:12:00\n    """\n    format = "%Y-%m-%d %H:%M:%S"\n    return dt.datetime.strptime(datetime_str, format)
-dir()
-scrape_game(2)
-print scrape_game(2)
-print scrape_game(100)
-dir()
-dir()
-def scrape_games_by_team(team, year="2012"):\n    """Palauttaa dictionaryn jossa avaimena joukkueen PELATTUJEN otteluiden\n    id:t, arvona ottelun 'nimi' (esim. 'Boston Bruins vs Boston (0-1-2)')."""\n    team = team.lower()\n    if not team in TEAMS or year > CURRENT_SEASON:\n        return {}\n\n    games = memcache.get(team + year)\n    if games:\n        logging.info("scrape_player_games(%s, %s) - Loytyi valimuistista."\n            % (team, year))\n        return games\n    logging.info("scrape_player_games(%s, %s) - Ei loytynyt valimuistista."\n            % (team, year))\n\n    url = ("http://sports.yahoo.com/nhl/teams/%s/schedule?"\n           "view=print_list&season=%s") % (team, year)\n    t0 = time.time()\n    response = urlfetch.fetch(url)\n    t0 = time.time() - t0\n    if response.status_code != 200:\n        raise web.notfound()\n\n    t1 = time.time()\n    root = html.fromstring(response.content)\n    rows = root.xpath("//tbody/tr[td[3]/a[contains(@href, 'recap')]]")\n    games = {}\n    for row in rows:\n        href = row.xpath("td[3]/a/@href")[0]\n        gid = href.split("gid=")[-1]  # TODO entä jos gid:n jälkeen toinen parametri?\n        games[gid] = row.xpath("td")[1].text_content().strip()\n\n    t1 = time.time() - t1\n    logging.info("""scrape_games_by_team(%s, %s):\n                 Haettiin HTML ajassa %f\n                 Skreipattiin data ajassa %f"""\n                 % (team, year, t0, t1))\n    # Deferred kutsuu add_cache-funktiota asynkronisesti:\n    deferred.defer(add_cache, key=team + year, value=games)\n    return games
-dir()
-a = scrape_games_by_team("bos")
-# -*-coding:utf-8-*-\n# Screippaustesti\n# TODO tyhjien palautusten sijaan virheilmoituksia?\n\n\nfrom lxml import html\nimport time\nimport datetime as dt\nimport logging\nimport sys\n# Jos ohjelmaa ajetaan itsenäisesti, ei voida käyttää app enginen moduuleita;\n# Urlfetch-, Memcache- ja Deferred-luokat mahdollistavat skreippausfunktioiden\n# testaamisen ilman App engineä.\ntry:\n    from google.appengine.api import urlfetch, memcache\n    from google.appengine.ext import deferred\nexcept ImportError:\n    logging.getLogger().setLevel(logging.DEBUG)\n    import urllib2\n\n    class Urlfetch:\n        def fetch(self, url):\n            response = urllib2.urlopen(url)\n\n            class Response:\n                def __init__(self, content, status_code):\n                    self.content = content\n                    self.status_code = status_code\n            return Response(response.read(), response.getcode())\n\n    class Memcache:\n        def get(self, *args, **kwargs):\n            pass\n\n        def add(self, *args, **kwargs):\n            pass\n\n    class Deferred:\n        def defer(self, *args, **kwargs):\n            pass\n    urlfetch = Urlfetch()\n    memcache = Memcache()\n\nCURRENT_SEASON = "2012"\nPLAYOFFS = False\nMONTHS = ["", "jan", "feb", "mar", "apr", "may", "jun",\n          "jul", "aug", "sep", "oct", "nov", "dec"]\nTEAMS = ["njd", "nyi", "nyr", "phi", "pit", "bos", "buf", "mon", "ott", "tor",\n         "car", "fla", "tam", "was", "wpg", "chi", "cob", "det", "nas", "stl",\n         "cgy", "col", "edm", "min", "van", "ana", "dal", "los", "pho", "san"]\nCITIES = ["new jersey", "ny islanders", "ny rangers", "philadelphia",\n          "pittsburgh", "boston", "buffalo", u"montréal", "ottawa", "toronto",\n          "carolina", "florida", "tampa bay", "washington", "winnipeg",\n          "chicago", "columbus", "detroit", "nashville", "st. louis",\n          "calgary", "colorado", "edmonton", "minnesota", "vancouver",\n          "anaheim", "dallas", "los angeles", "phoenix", "san jose"]\n\n# Eri sivuilta poimitaan erilaisia tilastoja:\nGAME_LOG_COLUMNS = ["opponent", "result", "g", "a", "pts", "+/-", "pim",\n                    "ppg", "hits", "bks", "ppa", "shg", "sha", "gw", ",gt",\n                    "sog", "pct"]\nBOXSCORE_COLUMNS_GOALIE = ["sa", "ga", "sv", "sv%", "pim", "toi"]\nBOXSCORE_COLUMNS = ["g", "a", "pts", "+/-", "pim", "s", "bs", "hits", "fw",\n                    "fl", "fo%", "shifts", "toi"]\n\n\ndef scrape_players(query=""):\n    """Skreippaa kaikki pelaajat, joiden nimi vastaa hakuehtoa. Oletuksena\n    haetaan kaikki pelaajat. Paluuarvona dictionary, jossa avaimena\n    pelaajan id, arvoina nimi, pelipaikka ja joukkue."""\n    players = memcache.get("query" + query)\n    if players is not None:\n        return players\n\n    url = "http://sports.yahoo.com/nhl/players?type=lastname&first=1&query="\n    t0 = time.time()\n    response = urlfetch.fetch(url + query)\n    t0 = time.time() - t0\n    if response.status_code != 200:\n        return None\n\n    t1 = time.time()\n    root = html.fromstring(response.content)\n    rows = root.xpath("//table//tr[contains(@class, 'ysprow') and count(td)=3]")\n    players = {}\n    for row in rows:\n        tds = row.getchildren()\n        pid = tds[0].getchildren()[0].attrib["href"].split("/")[-1]\n        name = tds[0].text_content().strip()\n        pos = tds[1].text\n        team = tds[2].getchildren()[0].attrib["href"].split("/")[-1]\n        players[pid] = dict(name=name, pos=pos, team=team)\n\n    memcache.add("query" + query, players, 60 * 60 * 24)\n    logging.info("""scrape_players(%s):\n                 Haettiin HTML ajassa %f\n                 Skreipattiin data ajassa %f"""\n                 % (query, t0, time.time() - t1))\n    return players\n\n\ndef scrape_players_and_stats(year="2012", playoffs=False,\n    positions=["C", "RW", "LW", "D", "G"]):\n    """Skreippaa valitun kauden kaikki pelaajat tilastoineen.\n    Paluuarvona dictionary jossa avaimena pelaajan id, arvona\n    joukkue, nimi ja koko kauden tilastot dictionaryssa."""\n    if year > CURRENT_SEASON or (year == CURRENT_SEASON and playoffs != PLAYOFFS):\n        return {}\n\n    url = "http://sports.yahoo.com/nhl/stats/byposition?pos=%s&year=%s"\n    year = "postseason_" + year if playoffs else "season_" + year\n    all_ids = {}\n\n    positions = map(str.upper, positions)\n\n    if any(pos not in ["C", "RW", "LW", "D", "G"] for pos in positions):\n        return {}  # Virheellinen pelipaikka\n\n    if "G" in positions:  # Maalivahdit täytyy skreipata eri sivulta.\n        if len(positions) > 1:  # Jos haetaan maalivahtien lisäksi muita pelipaikkoja..\n            positions.remove("G")\n            positions = [",".join(positions), "G"]\n    else:\n        positions = [",".join(positions)]\n\n    for position in positions:\n        url0 = url % (position, year)\n        print url0\n        response = urlfetch.fetch(url0)\n        if response.status_code != 200:\n            return {}\n        root = html.fromstring(response.content)\n\n        t0 = time.time()\n        ids = {}\n        rows = root.xpath("//table[count(tr)>10]/tr")\n        columns = [el.text_content().strip().lower() for el in rows[0].xpath("td[*]")]\n        columns = columns[1:]\n        for row in rows[1:]:\n            name = row.xpath("td/a")[0].text_content().lower()\n            pid = row.xpath("td/a")[0].attrib["href"].split("/")[-1]\n            stats = {"name": name}\n            i = 0\n            for td in row.xpath("td")[1:]:\n                text = td.text_content().strip().lower()\n                if text != "":\n                    stats[columns[i]] = text\n                    i += 1\n            ids[pid] = stats\n        all_ids = dict(all_ids.items() + ids.items())\n    return all_ids\n\n\ndef scrape_games_by_player(pid, year="2012"):\n    """Palauttaa pelaajan pelatut pelit. Paluuarvona dictionary, jonka avaimena\n    ottelun id, arvona pelaajan tilastot kyseisestä pelistä."""\n    pid = str(pid)\n    if year > CURRENT_SEASON:\n        return {}\n\n    games = memcache.get(pid + year)\n    if games:\n        logging.info("scrape_player_games(%s, %s) - Loytyi valimuistista."\n            % (pid, year))\n        return games\n    logging.info("scrape_player_games(%s, %s) - Ei loytynyt valimuistista."\n            % (pid, year))\n\n    url = "http://sports.yahoo.com/nhl/players/%s/gamelog?year=%s" % (pid, year)\n    t0 = time.time()\n    response = urlfetch.fetch(url)\n    t0 = time.time() - t0\n    if response.status_code != 200:\n        raise web.notfound()\n\n    t1 = time.time()\n    root = html.fromstring(response.content)\n    games = {}\n    rows = root.xpath("//table/tr[contains(@class, 'ysprow') and position() < last()]")\n    for row in rows:\n        game = {}\n        gid = row.xpath("td/a/@href")[0].split("gid=")[-1]\n        for i, td in enumerate(row.xpath("td")[1:-1]):\n            game[GAME_LOG_COLUMNS[i]] = td.text_content().strip()\n        games[gid] = game  # games == {"123":{"opponent":"asd","g":4,...}, "124":{...}, ...}\n\n    t1 = time.time() - t1\n    logging.info("""scrape_games_by_player(%s, %s):\n                 Haettiin HTML ajassa %f\n                 Skreipattiin data ajassa %f"""\n                 % (pid, year, t0, t1))\n    # Deferred kutsuu add_cache-funktiota asynkronisesti:\n    deferred.defer(add_cache, key=pid + year, value=games)\n    return games\n\n\ndef scrape_games_by_team(team, year="2012"):\n    """Palauttaa dictionaryn jossa avaimena joukkueen PELATTUJEN otteluiden\n    id:t, arvona ottelun 'nimi' (esim. 'Boston Bruins vs Boston (0-1-2)')."""\n    team = team.lower()\n    if not team in TEAMS or year > CURRENT_SEASON:\n        return {}\n\n    games = memcache.get(team + year)\n    if games:\n        logging.info("scrape_player_games(%s, %s) - Loytyi valimuistista."\n            % (team, year))\n        return games\n    logging.info("scrape_player_games(%s, %s) - Ei loytynyt valimuistista."\n            % (team, year))\n\n    url = ("http://sports.yahoo.com/nhl/teams/%s/schedule?"\n           "view=print_list&season=%s") % (team, year)\n    t0 = time.time()\n    response = urlfetch.fetch(url)\n    t0 = time.time() - t0\n    if response.status_code != 200:\n        raise web.notfound()\n\n    t1 = time.time()\n    root = html.fromstring(response.content)\n    rows = root.xpath("//tbody/tr[td[3]/a[contains(@href, 'recap')]]")\n    games = {}\n    for row in rows:\n        href = row.xpath("td[3]/a/@href")[0]\n        gid = href.split("gid=")[-1]  # TODO entä jos gid:n jälkeen toinen parametri?\n        games[gid] = row.xpath("td")[1].text_content().strip()\n\n    t1 = time.time() - t1\n    logging.info("""scrape_games_by_team(%s, %s):\n                 Haettiin HTML ajassa %f\n                 Skreipattiin data ajassa %f"""\n                 % (team, year, t0, t1))\n    # Deferred kutsuu add_cache-funktiota asynkronisesti:\n    deferred.defer(add_cache, key=team + year, value=games)\n    return games\n\n\ndef scrape_game(gid):\n    """Palauttaa dictionaryn, jossa hirveä läjä dataa ottelusta."""\n    gid = str(gid)\n\n    game = memcache.get(gid)\n    if game:\n        logging.info("scrape_game(%s) - Loytyi valimuistista."\n            % (gid))\n        return game\n    logging.info("scrape_game(%s) - Ei loytynyt valimuistista."\n            % (gid))\n\n    t0 = time.time()\n    url = "http://sports.yahoo.com/nhl/boxscore?gid=" + gid\n    response = urlfetch.fetch(url)\n    t0 = time.time() - t0\n    if response.status_code != 200:\n        raise web.notfound()\n\n    t1 = time.time()\n    root = html.fromstring(response.content)\n    game = {}\n    # Ottelun tulos:\n    game["away_team"] = root.xpath("//div[@class='away']//a")[0].attrib["href"].split("/")[-1]\n    game["home_team"] = root.xpath("//div[@class='home']//a")[0].attrib["href"].split("/")[-1]\n    game["away_score"] = root.xpath("//div[@class='away']/*")[0].text_content().strip()\n    game["home_score"] = root.xpath("//div[@class='home']/*")[0].text_content().strip()\n\n    # Maalit ja mahd. shootout:\n    periods = root.xpath("(//div[count(h5)>2])[1]/table")\n    goals, shootout = [], []\n    for i, period in enumerate(periods[:3]):  # Varsinaisen peliajan maalit\n        for tr in period.xpath("tbody/tr[count(td)>3]"):\n            tds = tr.xpath("td")\n            goal = {}\n            goal["period"] = i + 1\n            goal["time"] = tds[0].text_content().strip()\n            goal["team"] = tds[1].xpath("a/@href")[0].split("/")[-1]\n            goal["desc"] = tds[2].text_content().strip()\n            goal["score"] = tds[3].text_content().strip()\n            goals.append(goal)\n    if len(periods) > 3:\n        if len(periods[3].xpath("tbody/tr[count(td)>3]")) != 0:  # Jatkoaika\n            goal = {}\n            goal["period"] = 4\n            goal["time"] = tds[0].text_content().strip()\n            goal["team"] = tds[1].xpath("a/@href")[0].split("/")[-1]\n            goal["desc"] = tds[2].text_content().strip()\n            goal["score"] = tds[3].text_content().strip()\n            goals.append(goal)\n        else:  # Shootout\n            for tr in periods[4].xpath("tbody/tr"):\n                attempt = {}\n                attempt["team"] = tr.xpath("td/a/@href")[0].split("/")[-1]\n                attempt["desc"] = tr.xpath("td[last()]")[0].text_content().strip()\n                shootout.append(attempt)\n    game["goals"], game["shootout"] = goals, shootout\n\n    # Pelaajakohtaiset tilastot:\n    all_goalies = root.xpath("//div[contains(@class, 'goalies')]/table")\n    all_skaters = root.xpath("//div[contains(@class, 'skaters')]/table")\n    for i, team in enumerate(["away", "home"]):\n        team_goalies = {}\n        # Maalivahdit:\n        for tr in all_goalies[i].xpath("tbody/tr"):\n            goalie = {}\n            pid = tr.xpath(".//a/@href")[0].split("/")[-1]  # Id\n            goalie["name"] = tr.xpath(".//a")[0].text       # Nimi\n            for j, td in enumerate(tr.xpath("td")[1:]):     # Tilastot\n                goalie[BOXSCORE_COLUMNS_GOALIE[j]] = td.text_content().strip()\n            team_goalies[pid] = goalie\n        # Loput:\n        team_skaters = {}\n        for tr in all_skaters[i].xpath("tbody/tr"):\n            skater = {}\n            pid = tr.xpath(".//a/@href")[0].split("/")[-1]  # Id\n            skater["name"] = tr.xpath(".//a")[0].text       # Nimi\n            for k, td in enumerate(tr.xpath("td")[1:]):     # Tilastot\n                skater[BOXSCORE_COLUMNS[k]] = td.text_content().strip()\n            team_skaters[pid] = skater\n        game[team] = dict(goalies=team_goalies, skaters=team_skaters)\n\n    t1 = time.time() - t1\n    logging.info("""scrape_game(%s):\n                 Haettiin HTML ajassa %f\n                 Skreipattiin data ajassa %f""" % (gid, t0, t1))\n    memcache.add(gid, game)\n    return game\n\n\ndef scrape_schedule(season="20122013", playoffs=False):\n    """Skreippaa kauden tulevien pelien alkamisajat ja joukkueet.\n\n    Paluuarvo on muotoa\n    {"ana": [\n        {"time": "2012-02-06 21:30:00", "home":"ana", "away":"bos"},\n        {"time": "2012-02-07 16:00:00", "home":"cal", "away":"ana"},\n        ...],\n     "bos": [\n        {"time": "2012-02-06 21:30:00", "home:"ana", "away":"bos"},\n        ...],\n     ...}\n    """\n    schedule = memcache.get("schedule")\n    if schedule is not None:\n        return schedule\n\n    url = "http://nhl.com/ice/schedulebyseason.htm?season=%s"\n    if playoffs:\n        url += "&gameType=3"\n    t0 = time.time()\n    page = urlfetch.fetch(url)\n    t0 = time.time() - t0\n\n    t1 = time.time()\n    root = html.fromstring(page.content)\n    schedule = {team: [] for team in TEAMS}\n    rows = root.xpath("//div[@class='contentBlock']/table[1]/tbody/tr")\n    for row in rows:\n        if row.xpath("td[4]/*"):\n            date_str = row.xpath("td[1]/div[1]/text()")[0][4:]\n            time_str = row.xpath("td[4]/div[1]/text()")[0].replace(" ET", "")\n            datetime_str = str(str_to_date(date_str + " " + time_str))\n        else:\n            # Joidenkin pelien alkamiskellonaika ei ole tiedossa (pvm on),\n            # mitäköhän niille tekisi?\n            datetime_str = ""\n        home_city = row.xpath("td[2]")[0].text_content().lower()\n        away_city = row.xpath("td[3]")[0].text_content().lower()\n        home_team = TEAMS[CITIES.index(home_city)]\n        away_team = TEAMS[CITIES.index(away_city)]\n        game = {"time": datetime_str, "home": home_team, "away": away_team}\n        schedule[home_team].append(game)\n        schedule[away_team].append(game)\n\n    logging.info("""scrape_schedule():\n                 Haettiin HTML ajassa %f\n                 Skreipattiin data ajassa %f""" % (t0, time.time() - t1))\n    memcache.add("schedule", schedule, 60 * 60 * 12)\n    return schedule\n\n\ndef get_next_game(team=None, pid=None):\n    """Palauttaa dictionaryn, jossa joukkueen/pelaajan seuraavan pelin\n    alkamisaika, kotijoukkue ja vierasjoukkue. Esim:\n    {"time": "2013-02-28 10:30:00", "home":"ana", "away":"bos"}}\n    """\n    if pid and not team:\n        team = scrape_players()[pid]["team"]\n    return min(scrape_schedule()[team], key=lambda x: x["time"])\n\n\ndef get_latest_game(team=None, pid=None):\n    """Palauttaa joukkueen/pelaajan viimeisimmän pelatun pelin id:n."""\n    if team:\n        return sorted(scrape_games_by_team(team))[-1]\n    return sorted(scrape_games_by_player(pid))[-1]\n\n\ndef add_cache(key, value):\n    """Lisää arvon välimuistiin, määrittää vanhenemisajan otteluohjelman\n    mukaan. Tallennettava arvo voi olla joko pelaajan tai joukkueen pelatut\n    pelit."""\n    ident, year = key[:-4], key[-4:]\n    if year != CURRENT_SEASON:\n        # Edellisten kausien pelattujen pelien tiedot eivät vanhene:\n        memcache.set(key, value)\n    else:\n        # Muuten asetetaan vanhenemisaika seuraavan ottelun mukaan:\n        previous = memcache.get(key + "b")\n        if previous != None and len(value) == previous:\n            # Jos arvo ei ole muuttunut, laitetaan vanhenemisajaksi 10 minuuttia:\n            memcache.set(key, value, 60 * 10)\n        else:\n            # Arvo on muuttunut, selvitetään seuraavan ottelun ajankohta:\n            if ident.isalpha():\n                next_game_time = get_next_game(team=ident)["time"]\n            else:\n                next_game_time = get_next_game(pid=ident)["time"]\n            # Välimuistin arvo vanhenee 2 tuntia pelin alkamisen jälkeen:\n            game_end_time = isostr_to_date(next_game_time) + dt.timedelta(\n                hours=2)\n            time_diff = (game_end_time - dt.datetime.utcnow()).seconds\n            memcache.set(key, value, time_diff)\n            memcache.set(key + "b", len(value))\n            logging.info("""Tallennettiin valimuistiin\n                         Avain %s\n                         Vanhenemisaika %ds""" % (key, time_diff))\n\n\ndef toi_to_sec(toi):\n    """Peliaka sekunteiksi.\n\n    >>> toi_to_sec("22:18")\n    1338\n    """\n    splits = toi.split(":")\n    return int(splits[0]) * 60 + int(splits[1])\n\n\ndef sec_to_toi(sec):\n    """Sekunnit peliajaksi.\n\n    >>> print sec_to_toi("1234")\n    20:34\n    """\n    sec = int(sec)\n    return "%d:%d" % (sec / 60, sec % 60)\n\n\ndef str_to_date(datetime_str, zone=-5):\n    """Ottaa merkkijonon muotoa "FEB 6, 2013 7:30 PM", palauttaa\n    datetime-objektin. Zone-parametri määrittää merkkijonon aikavyöhykkeen;\n    Jos zone on -5, paluuarvoon lisätään 5 tuntia jolloin paluuarvon aika-\n    vyöhyke on GMT+-0.\n\n    >>> print str_to_date("FEB 6, 2013 7:30 PM", zone=-1)\n    2013-02-06 20:30:00\n    >>> print str_to_date("FEB 28, 2013 12:00 AM", zone=0)\n    2013-02-28 00:00:00\n    """\n    format = "%b %d, %Y %I:%M %p"\n    return dt.datetime.strptime(datetime_str, format) - dt.timedelta(hours=zone)\n\n\ndef isostr_to_date(datetime_str):\n    """Ottaa ISO-formatoidun merkkijonon, palauttaa datetime-objektin.\n\n    >>> print isostr_to_date("2013-02-28 16:12:00")\n    2013-02-28 16:12:00\n    """\n    format = "%Y-%m-%d %H:%M:%S"\n    return dt.datetime.strptime(datetime_str, format)
-scrape_games_by_team(bos)
-scrape_games_by_team("bos")
-a = scrape_games_by_team("bos")
-a
-print a
-a = scrape_games_by_team("min")
-a
-print a
-!ls
-?
-ls
-%pwd
-cd ..
-ls
-cd pucktracker/
-ls
-!g status
-!git status
-ls
-%lsmagic
-dir
-()
-;
-dir()
-import os
-def build_post_index():\n    ''' Scan ./posts/ folder, add all posts to list and return it '''\n    found_posts = []\n\n    i = 1  # TODO: nicer way to loop?\n    while True:\n        find_path = "./posts/" + str(i) + ".html"\n        if os.path.exists(find_path):\n            found_posts.append(find_path)\n            i = i + 1\n        else:\n            return found_posts\n        #   found_posts.append(find_path)
-%paste
